@inproceedings{iso18004,
  title     = {{ISO/IEC 18004: Information technology -- Automatic identification and data capture techniques -- QR code bar code symbology specification}},
  booktitle = {ISO/IEC 18004:2000},
  author    = {{International Organization for Standardization}},
  year      = {2000},
}

//LLM
@article{PLMsPreTraining,
   title={Pre-trained models for natural language processing: A survey},
   volume={63},
   ISSN={1869-1900},
   url={http://dx.doi.org/10.1007/s11431-020-1647-3},
   DOI={10.1007/s11431-020-1647-3},
   number={10},
   journal={Science China Technological Sciences},
   publisher={Springer Science and Business Media LLC},
   author={Qiu, XiPeng and Sun, TianXiang and Xu, YiGe and Shao, YunFan and Dai, Ning and Huang, XuanJing},
   year={2020},
   month=sep, pages={1872–1897} 

}

@online{krannig2020deep,
  author       = {Krannig, Simon},
  title        = {Deep Learning schafft Serverstabilität und verbessert Netzwerkarchitekturen},
  date         = {2020-03-19},
  howpublished = {Blog-Beitrag, Adacor Hosting GmbH, Bereich „News \& Trends“},
  url          = {https://blog.adacor.com/deep-learning-schafft-serverstabilitaet-und-verbessert-netzwerkarchitekturen_8414.html},
  note         = {Abgerufen am \today},
}


@inproceedings{AttentionIsAllYouNeed,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{SCHMIDHUBER201585,
  title = {Deep learning in neural networks: An overview},
  journal = {Neural Networks},
  volume = {61},
  pages = {85-117},
  year = {2015},
  issn = {0893-6080},
  doi = {https://doi.org/10.1016/j.neunet.2014.09.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608014002135},
  author = {Jürgen Schmidhuber},
  keywords = {Deep learning, Supervised learning, Unsupervised learning, Reinforcement learning, Evolutionary computation},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.}
}

@INPROCEEDINGS{8666928,
  author={Wang, Wei and Gang, Jianxun},
  booktitle={2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={Application of Convolutional Neural Network in Natural Language Processing}, 
  year={2018},
  volume={},
  number={},
  pages={64-70},
  abstract={Convolutional neural network (Convolutionl Neural Network, CNN) is a multiple-layer neural network method to learn hierarchical characteristic of data. In recent years, CNN has developed rapidly in the design and calculation of natural language processing (NLP). This paper introduces the principles models and applications of CNN in natural language processing tasks and presents some personal insights into the use of CNN methods in NLP task processing.},
  keywords={Task analysis;Natural language processing;Semantics;Neural networks;Context modeling;Feature extraction;Convolution;Natural language processing;Convolution neural network;Applications},
  doi={10.1109/ICISCAE.2018.8666928},
  ISSN={},
  month={July},
}

@article{PLMsPaper,
  title={Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey},
  author={Bonan Min and Hayley Ross and Elior Sulem and Amir Pouran Ben Veyseh and Thien Huu Nguyen and Oscar Sainz and Eneko Agirre and Ilana Heinz and Dan Roth},
  journal={ACM Computing Surveys},
  year={2021},
  volume={56},
  pages={1 - 40},
  url={https://api.semanticscholar.org/CorpusID:240420063}
}

@misc{brown2020languagemodelsfewshotlearners,
  title={Language Models are Few-Shot Learners}, 
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year={2020},
  eprint={2005.14165},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2005.14165}, 
}

@misc{LLMTaxonomyPrompting,
  title={Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey}, 
  author={Chen Ling and Xujiang Zhao and Jiaying Lu and Chengyuan Deng and Can Zheng and Junxiang Wang and Tanmoy Chowdhury and Yun Li and Hejie Cui and Xuchao Zhang and Tianjiao Zhao and Amit Panalkar and Dhagash Mehta and Stefano Pasquali and Wei Cheng and Haoyu Wang and Yanchi Liu and Zhengzhang Chen and Haifeng Chen and Chris White and Quanquan Gu and Jian Pei and Carl Yang and Liang Zhao},
  year={2024},
  eprint={2305.18703},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2305.18703}, 
}

@article{Inference,
  title={LLM Inference Unveiled: Survey and Roofline Model Insights},
  author={Zhihang Yuan and Yuzhang Shang and Yang Zhou and Zhen Dong and Chenhao Xue and Bingzhe Wu and Zhikai Li and Qingyi Gu and Yong Jae Lee and Yan Yan and Beidi Chen and Guangyu Sun and Kurt Keutzer},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.16363},
  url={https://api.semanticscholar.org/CorpusID:268032253}
}

@INPROCEEDINGS{10825265,
  author={Keluskar, Aryan and Bhattacharjee, Amrita and Liu, Huan},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Do LLMs Understand Ambiguity in Text? A Case Study in Open-world Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={7485-7490},
  keywords={Sentiment analysis;Uncertainty;Large language models;Natural languages;Focusing;Big Data;Feature extraction;Question answering (information retrieval);Data models;Best practices;ambiguity;sensitivity;LLM;large language model;question-answering},
  doi={10.1109/BigData62323.2024.10825265}
}

@book{ExplainableLLM,
  title={A Comprehensive Guide to Explainable AI: From Classical Models to LLMs}, 
  author={Weiche Hsieh and Ziqian Bi and Chuanqi Jiang and Junyu Liu and Benji Peng and Sen Zhang and Xuanhe Pan and Jiawei Xu and Jinlang Wang and Keyu Chen and Pohsun Feng and Yizhu Wen and Xinyuan Song and Tianyang Wang and Ming Liu and Junjie Yang and Ming Li and Bowen Jing and Jintao Ren and Junhao Song and Hong-Ming Tseng and Yichao Zhang and Lawrence K. Q. Yan and Qian Niu and Silin Chen and Yunze Wang and Chia Xin Liang},
  year={2024},
  eprint={2412.00800},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2412.00800}, 
}

@misc{li2024personalllmagentsinsights,
  title={Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security}, 
  author={Yuanchun Li and Hao Wen and Weijun Wang and Xiangyu Li and Yizhen Yuan and Guohong Liu and Jiacheng Liu and Wenxing Xu and Xiang Wang and Yi Sun and Rui Kong and Yile Wang and Hanfei Geng and Jian Luan and Xuefeng Jin and Zilong Ye and Guanjing Xiong and Fan Zhang and Xiang Li and Mengwei Xu and Zhijun Li and Peng Li and Yang Liu and Ya-Qin Zhang and Yunxin Liu},
  year={2024},
  eprint={2401.05459},
  archivePrefix={arXiv},
  primaryClass={cs.HC},
  url={https://arxiv.org/abs/2401.05459}, 
}

//RAG
@misc{ibm2023rag,
  author       = {{IBM Research}},
  title        = {Retrieval-Augmented Generation (RAG): Why adding search to generative AI makes it better},
  year         = {2023},
  url          = {https://research.ibm.com/blog/retrieval-augmented-generation-RAG},
  note         = {Accessed: 2025-05-20}
}

@article{Hu2024LLMEvaluation,
  author    = {Taojun Hu and Xiao-Hua Zhou},
  title     = {Unveiling LLM Evaluation Focused on Metrics: Challenges and Solutions},
  journal   = {arXiv preprint},
  volume    = {arXiv:2404.09135},
  year      = {2024},
  month     = {April},
  url       = {https://arxiv.org/pdf/2404.09135},
  urldate = {2025-03-12},
  note      = {Version 1, submitted on 14 April 2024}
}

@inproceedings{Lin2004,
  author    = {Chin-Yew Lin},
  title     = {ROUGE: A Package for Automatic Evaluation of Summaries},
  booktitle = {Text Summarization Branches Out},
  year      = {2004},
  month     = {Jul},
  address   = {Barcelona, Spain},
  publisher = {Association for Computational Linguistics},
  pages     = {74--81},
  url       = {https://aclanthology.org/W04-1013/},
  urldate   = {2025-03-27},
  doi       = {10.3115/1075163.1075200}
}

@article{Li2024,
  author    = {Chenjie Li and Dan Zhang and Jin Wang},
  title     = {LLM-assisted Labeling Function Generation for Semantic Type Detection},
  journal   = {arXiv preprint},
  year      = {2024},
  institution = {Illinois Institute of Technology, Megagon Labs},
  url       = {https://arxiv.org/abs/2408.16173},
  urldate   = {2025-03-31}
}

@inproceedings{Ghamrawi2005CollectiveMLC,
  author    = {Nadia Ghamrawi and Andrew McCallum},
  title     = {Collective Multi-Label Classification},
  booktitle = {Proceedings of the University of Massachusetts Amherst},
  year      = {2005},
  publisher = {University of Massachusetts Amherst},
  address   = {Amherst, Massachusetts, USA},
  url       = {https://scholarworks.umass.edu/server/api/core/bitstreams/ee4f8c19-e9e4-4a0f-bb2a-669cdfe09706/content},
  urldate = {2025-03-11}
}

@article{adamson2023ml_ehr,
  author    = {Adamson, Blythe and Waskom, Michael and Blarre, Auriane and Kelly, Jonathan and Krismer, Konstantin and Nemeth, Sheila and Gippetti, James and Ritten, John and Harrison, Katherine and Ho, George and Linzmayer, Robin and Bansal, Tarun and Wilkinson, Samuel and Amster, Guy and Estola, Evan and Benedum, Corey M. and Fidyk, Erin and Estévez, Melissa and Shapiro, Will and Cohen, Aaron B.},
  title     = {Approach to Machine Learning for Extraction of Real-World Data Variables from Electronic Health Records},
  journal   = {Frontiers in Pharmacology},
  volume    = {14},
  pages     = {1180962},
  year      = {2023},
  url       = {https://www.frontiersin.org/journals/pharmacology/articles/10.3389/fphar.2023.1180962/full},
  urldate = {2025-03-07},
  publisher = {Frontiers},
}

@misc{srivastava2024medpromptextract,
  title = {MedPromptExtract (Medical Data Extraction Tool): Anonymization and Hi-fidelity Automated data extraction using NLP and prompt engineering},
  author = {Srivastava, Roomani and Prasad, Suraj and Bhat, Lipika and Deshpande, Sarvesh and Das, Barnali and Jadhav, Kshitij},
  year = {2024},
  howpublished = {arXiv preprint arXiv:2405.02664v3},
  url = {https://arxiv.org/abs/2405.02664v3},
  urldate = {2025-03-07},
}

@article{Hein2025,
  author    = {David Hein and Alana Christie and Michael Holcomb and Bingqing Xie and AJ Jain and Joseph Vento and Neil Rakheja and Ameer Hamza Shakur and Scott Christley and Lindsay G. Cowell and James Brugarolas and Andrew Jamieson and Payal Kapur},
  title     = {Prompts to Table: Specification and Iterative Refinement for Clinical Information Extraction with Large Language Models},
  journal   = {medRxiv},
  year      = {2025},
  note      = {Preprint, not peer-reviewed},
  url       = {https://doi.org/10.1101/2025.02.11.25322107},
  urldate   = {2025-03-07}
}

@article{rifkin2004onevsall,
  title     = {In Defense of One-Vs-All Classification},
  author    = {Rifkin, Ryan M. and Klautau, Aldebaro},
  journal   = {Journal of Machine Learning Research},
  volume    = {5},
  pages     = {101--141},
  year      = {2004},
  publisher = {MIT Press}
}

@article{Lipton2014Thresholding,
  author    = {Zachary Chase Lipton and Charles Elkan and Balakrishnan Narayanaswamy},
  title     = {Thresholding Classifiers to Maximize F1 Score},
  journal   = {arXiv preprint},
  volume    = {arXiv:1402.1892},
  year      = {2014},
  url       = {https://arxiv.org/abs/1402.1892},
  urldate = {2025-03-07},
}

@article{Li2024LLMJudge,
  author    = {Dawei Li and Bohan Jiang and Liangjie Huang and Alimohammad Beigi and Chengshuai Zhao and Zhen Tan and Amrita Bhattacharjee and Yuxuan Jiang and Canyu Chen and Tianhao Wu and Kai Shu and Lu Cheng and Huan Liu},
  title     = {From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge},
  journal   = {arXiv preprint},
  volume    = {2411.16594},
  year      = {2024},
  url       = {https://arxiv.org/abs/2411.16594},
  urldate = {2025-03-12}
}

@article{wolpert1992stacked,
  author = {Wolpert, David H.},
  title = {Stacked Generalization},
  journal = {Neural Networks},
  volume = {5},
  number = {2},
  pages = {241--259},
  year = {1992},
  publisher = {Pergamon Press Ltd.},
  url = {https://www.researchgate.net/publication/222467943_Stacked_Generalization},
  urldate = {2025-03-12}
}

@article{Özbligin2025Stacking,
  author = {Özbilgin, Ferdi and Durmuş, Fatih},
  year = {2025},
  month = {03},
  pages = {1-20},
  title = {Fine-Tuned Machine Learning Classifiers for Diagnosing Parkinson’s Disease Using Vocal Characteristics:A Comparative Analysis},
  volume = {15},
  journal = {Diagnostics},
  url = {https://www.researchgate.net/publication/389653282_Fine-Tuned_Machine_Learning_Classifiers_for_Diagnosing_Parkinson's_Disease_Using_Vocal_CharacteristicsA_Comparative_Analysis},
  urldate = {2025-03-12}
}

@inproceedings{Liu2016HowNotToEvaluate,
  author    = {Chia-Wei Liu and Ryan Lowe and Iulian Serban and Mike Noseworthy and Laurent Charlin and Joelle Pineau},
  title     = {How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2016},
  address   = {Austin, Texas},
  editor    = {Jian Su and Kevin Duh and Xavier Carreras},
  publisher = {Association for Computational Linguistics},
  pages     = {2122--2132},
  url       = {https://aclanthology.org/D16-1230/},
  urldate = {2025-03-12}
}

@article{Krumdick2025NoFreeLabels,
  author    = {M. Krumdick and C. Lovering and V. Reddy and S. Ebner and C. Tanner},
  title     = {No Free Labels: Limitations of LLM-as-a-Judge Without Human Grounding},
  journal   = {arXiv preprint},
  volume    = {arXiv:2503.05061},
  year      = {2025},
  url       = {https://arxiv.org/abs/2503.05061},
  urldate = {2025-03-12}
}

@article{Li2024MATEval,
  author    = {Yu Li and Shenyu Zhang and Rui Wu and Xiutian Huang and Yongrui Chen and Wenhao Xu and Guilin Qi and Dehai Min},
  title     = {MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation},
  journal   = {arXiv preprint arXiv:2403.19305},
  year      = {2024},
  url       = {https://arxiv.org/pdf/2403.19305},
  urldate = {2025-03-12}
}

@article{schroer2021systematic,
  title={A Systematic Literature Review on Applying CRISP-DM Process Model},
  author={Schr{\"o}er, Christoph and Kruse, Fabian and G{\"o}rke, Oliver},
  journal={},
  year={2021},
  url={https://www.sciencedirect.com/science/article/pii/S1877050921002416},
  urldate={2025-02-25}
}